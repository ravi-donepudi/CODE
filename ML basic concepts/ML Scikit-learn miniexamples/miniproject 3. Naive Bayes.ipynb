{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import HashingVectorizer, TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn import metrics\n",
    "\n",
    "from scipy.stats import sem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "news = fetch_20newsgroups(subset='all');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n"
     ]
    }
   ],
   "source": [
    "print(news.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: Mamatha Devineni Ratnam <mr47+@andrew.cmu.edu>\n",
      "Subject: Pens fans reactions\n",
      "Organization: Post Office, Carnegie Mellon, Pittsburgh, PA\n",
      "Lines: 12\n",
      "NNTP-Posting-Host: po4.andrew.cmu.edu\n",
      "\n",
      "\n",
      "\n",
      "I am sure some bashers of Pens fans are pretty confused about the lack\n",
      "of any kind of posts about the recent Pens massacre of the Devils. Actually,\n",
      "I am  bit puzzled too and a bit relieved. However, I am going to put an end\n",
      "to non-PIttsburghers' relief with a bit of praise for the Pens. Man, they\n",
      "are killing those Devils worse than I thought. Jagr just showed you why\n",
      "he is much better than his regular season stats. He is also a lot\n",
      "fo fun to watch in the playoffs. Bowman should let JAgr have a lot of\n",
      "fun in the next couple of games since the Pens are going to beat the pulp out of Jersey anyway. I was very disappointed not to see the Islanders lose the final\n",
      "regular season game.          PENS RULE!!!\n",
      "\n",
      " rec.sport.hockey\n"
     ]
    }
   ],
   "source": [
    "print(news.data[0], news.target_names[news.target[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18846 18846 20\n"
     ]
    }
   ],
   "source": [
    "print(len(news.data), len(news.target), len(news.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14134 4712 14134 4712\n"
     ]
    }
   ],
   "source": [
    "#Split the dataset into train+test parts\n",
    "SPLIT_PERCENT = 0.75\n",
    "split_number = int(0.75*len(news.target))\n",
    "X_train = news.data[:split_number]\n",
    "X_test = news.data[split_number:]\n",
    "y_train = news.target[:split_number]\n",
    "y_test = news.target[split_number:]\n",
    "print(len(X_train), len(X_test), len(y_train), len(y_test))\n",
    "#Can also use train_test_split\n",
    "#X_train, X_test, Y_train, Y_test = train_test_split(news.data, news.target, train_size=0.75, random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_1 = Pipeline([('vect', CountVectorizer()), \n",
    "                  ('clf', MultinomialNB())])\n",
    "clf_2 = Pipeline([('vect', HashingVectorizer(alternate_sign=False)),\n",
    "                  ('clf',MultinomialNB())])\n",
    "clf_3 = Pipeline([('vect', TfidfVectorizer()),\n",
    "                  ('clf', MultinomialNB())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.85782493 0.85725657 0.84664367 0.85911382 0.8458477 ]\n",
      "Mean score: 0.853 ± 0.003\n",
      "[0.75517241 0.77659857 0.77076148 0.78508888 0.76200584]\n",
      "Mean score: 0.770 ± 0.005\n",
      "[0.84482759 0.85990979 0.84558238 0.85990979 0.84213319]\n",
      "Mean score: 0.850 ± 0.004\n"
     ]
    }
   ],
   "source": [
    "def evaluate_cross_validation(clf, X,y, K=5):\n",
    "    cv = KFold(n_splits=K, random_state=0, shuffle=True)\n",
    "    scores = cross_val_score(clf, X,y, cv = cv)\n",
    "    print(scores)\n",
    "    print('Mean score: {0:.3f} ± {1:.3f}'.format(np.mean(scores), sem(scores)))\n",
    "for clf in [clf_1, clf_2, clf_3]:\n",
    "    evaluate_cross_validation(clf, news.data,news.target, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set:\n",
      "0.9267015706806283\n",
      "Accuracy on test set:\n",
      "0.8425297113752123\n",
      "The classfication report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.87      0.88       216\n",
      "           1       0.61      0.85      0.71       246\n",
      "           2       0.94      0.12      0.21       274\n",
      "           3       0.61      0.85      0.71       235\n",
      "           4       0.89      0.87      0.88       231\n",
      "           5       0.75      0.90      0.82       225\n",
      "           6       0.88      0.68      0.77       248\n",
      "           7       0.90      0.88      0.89       275\n",
      "           8       0.94      0.94      0.94       226\n",
      "           9       0.97      0.94      0.96       250\n",
      "          10       0.97      0.98      0.98       257\n",
      "          11       0.87      0.98      0.92       261\n",
      "          12       0.85      0.86      0.85       216\n",
      "          13       0.90      0.92      0.91       257\n",
      "          14       0.91      0.93      0.92       246\n",
      "          15       0.81      0.95      0.87       234\n",
      "          16       0.82      0.94      0.88       218\n",
      "          17       0.90      0.99      0.94       236\n",
      "          18       0.84      0.85      0.84       213\n",
      "          19       0.94      0.54      0.69       148\n",
      "\n",
      "    accuracy                           0.84      4712\n",
      "   macro avg       0.86      0.84      0.83      4712\n",
      "weighted avg       0.86      0.84      0.83      4712\n",
      "\n",
      "The confusion matrix\n",
      "[[187   1   0   0   0   0   0   0   0   0   1   0   2   2   0  16   1   2\n",
      "    1   3]\n",
      " [  0 210   0   6   0  11   4   0   1   1   0   4   1   2   1   0   0   1\n",
      "    4   0]\n",
      " [  0  69  32  90  11  42   0   1   1   1   0   9   4   1   4   3   0   0\n",
      "    5   1]\n",
      " [  0  10   1 199   5   6   4   0   0   1   0   3   3   0   1   0   1   0\n",
      "    1   0]\n",
      " [  0   5   0   8 200   2   4   0   0   0   0   4   6   1   1   0   0   0\n",
      "    0   0]\n",
      " [  0  15   0   2   1 203   0   1   0   1   0   0   0   1   1   0   0   0\n",
      "    0   0]\n",
      " [  0   9   0  11   4   1 169  19   2   1   3   5   9   3   1   1   4   3\n",
      "    3   0]\n",
      " [  1   2   0   1   0   1   7 241   4   1   0   0   2   2   1   0   5   2\n",
      "    5   0]\n",
      " [  0   0   0   1   0   1   2   2 212   0   0   1   0   1   1   1   1   2\n",
      "    1   0]\n",
      " [  0   1   0   0   1   0   0   1   2 235   3   0   2   2   0   1   1   1\n",
      "    0   0]\n",
      " [  0   1   0   0   0   0   0   0   0   1 253   0   1   0   0   0   0   0\n",
      "    1   0]\n",
      " [  0   2   0   0   0   0   0   0   0   0   0 255   0   0   0   0   2   1\n",
      "    1   0]\n",
      " [  0   8   0   3   2   1   0   1   0   0   1   4 185   3   7   0   0   0\n",
      "    1   0]\n",
      " [  1   3   0   0   0   0   0   1   1   0   0   1   1 236   3   4   4   1\n",
      "    1   0]\n",
      " [  0   7   0   0   1   1   2   0   0   0   0   0   0   1 230   0   2   1\n",
      "    1   0]\n",
      " [  1   3   0   2   0   0   0   1   0   0   0   1   0   2   0 223   0   1\n",
      "    0   0]\n",
      " [  0   0   1   0   0   0   1   0   2   0   0   2   0   0   0   0 206   3\n",
      "    3   0]\n",
      " [  0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 234\n",
      "    1   0]\n",
      " [  1   0   0   1   0   0   0   1   1   0   0   3   1   1   1   2  13   7\n",
      "  180   1]\n",
      " [ 17   0   0   0   0   1   0   0   0   0   0   0   1   3   1  26  11   2\n",
      "    6  80]]\n"
     ]
    }
   ],
   "source": [
    "def train_and_evaluate(clf, X_train, X_test, y_train, y_test):\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(\"Accuracy on training set:\")\n",
    "    print(clf.score(X_train, y_train))\n",
    "    print(\"Accuracy on test set:\")\n",
    "    print(clf.score(X_test, y_test))\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(\"The classfication report:\")    \n",
    "    print(metrics.classification_report(y_test,y_pred))\n",
    "    print(\"The confusion matrix\")\n",
    "    print(metrics.confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "train_and_evaluate(clf_1, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
